# Ingestion Layer Documentation

Lovdata RAG System â€“ Ingestion Layer  
Production-ready ingestion pipeline for Norwegian legal documents.

The ingestion layer is responsible for **collecting, preprocessing, chunking, embedding, and storing legal documents** into the vector database used by the RAG backend.

---

## ğŸ¯ Features

- âœ… Lovdata legal document ingestion  
- âœ… Robust preprocessing & text cleaning  
- âœ… Advanced chunking (parentâ€“child, token-aware)  
- âœ… Embedding generation (BGE / OpenAI / Azure OpenAI)  
- âœ… Milvus vector database storage  
- âœ… Idempotent & repeatable ingestion runs  
- âœ… Structured metadata for traceability  
- âœ… Logging & error handling  
- âœ… Production-ready modular architecture  

---

## ğŸ“ Project Structure

```text
DIGIRETT-AI-AGENT/
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ .gitkeep
â”‚   â””â”€â”€ README.md
â”œâ”€â”€ ingestion/
â”‚   â””â”€â”€ src/
â”‚       â”œâ”€â”€ processors/
â”‚       â”‚   â”œâ”€â”€ chunker.py
â”‚       â”‚   â”œâ”€â”€ embedder_sagemaker.py
â”‚       â”‚   â””â”€â”€ text_processor.py
â”‚       â”œâ”€â”€ storage/
â”‚       â”‚   â”œâ”€â”€ milvus_store.py
â”‚       â”‚   â””â”€â”€ supabase_store.py
â”‚       â”œâ”€â”€ verify/
â”‚       â”‚   â”œâ”€â”€ check_chunker.py
â”‚       â”‚   â”œâ”€â”€ del_milvus.py
â”‚       â”‚   â”œâ”€â”€ verify_milvus.py
â”‚       â”‚   â””â”€â”€ verify_sagemaker.py
â”‚       â”œâ”€â”€ __init__.py
â”‚       â”œâ”€â”€ config.py
â”‚       â””â”€â”€ main.py
â”œâ”€â”€ tests/
â”‚   â”œâ”€â”€ demo_testing.py
â”‚   â”œâ”€â”€ test_bge_embedding.py
â”‚   â”œâ”€â”€ test_collector.py
â”‚   â”œâ”€â”€ test_health.py
â”‚   â”œâ”€â”€ test_milvus_store.py
â”‚   â””â”€â”€ test_supabase_store.py
â”œâ”€â”€ .gitignore
â”œâ”€â”€ ecosystem.config.js
â”œâ”€â”€ README.md
â””â”€â”€ requirements.txt

ğŸš€ Quick Start

1ï¸âƒ£ Install Dependencies

cd ingestion
python -m venv .venv
source .venv/bin/activate   # On Windows: .venv\Scripts\activate
pip install -r requirements.txt

2ï¸âƒ£ Configure Environment

Copy .env.example to .env and update:

# Lovdata
# Company-specific raw XML data (example)
DATA_PATH=./data/raw_xml   # contains ~53 XML files

**# Embeddings**

EMBEDDING_PROVIDER=azure_openai
AZURE_OPENAI_ENDPOINT=https://your-resource.openai.azure.com/
AZURE_OPENAI_API_KEY=your-api-key
AZURE_OPENAI_EMBEDDING_DEPLOYMENT=bge-m3

**# Milvus**
MILVUS_HOST=localhost
MILVUS_PORT=19530
MILVUS_COLLECTION=lovdata_legal_docs

**# Chunking**

CHUNK_SIZE=512
CHUNK_OVERLAP=64

3ï¸âƒ£ Run the Ingestion Pipeline

Standard Ingestion Run

--- python -m ingestion.src.main

This command will:

Fetch legal documents from Lovdata

Clean and normalize text

Apply chunking strategy

Generate embeddings

Store vectors and metadata in Milvus

ğŸ§ª Testing
Run ingestion tests:

pytest tests/-demo_testing

ğŸ§  Ingestion Flow

raw_files
    â†“
Raw Document Loader
    â†“
Text Cleaning & Normalization
    â†“
Chunking (Parentâ€“Child / Token-Aware)
    â†“
Embedding Generation
    â†“
Milvus Vector Store

ğŸ§© Chunking Strategy

Parentâ€“Child Chunking
Parent chunk: legal section or article

Child chunks: smaller semantic units used for embeddings

Token-Aware Chunking
Prevents exceeding LLM token limits

Preserves semantic coherence

Dynamic Chunk Sizes
Adjusts chunk size based on document structure

ğŸ“Š Logging & Monitoring

Logs are stored under logs/

tail -f logs/ingestion.log
Log Levels

DEBUG

INFO

WARNING

ERROR

Version: 1.0.0
Last Updated: January 2026
